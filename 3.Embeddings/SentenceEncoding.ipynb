{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNg0T5hmehk9J6h4NFmyIfr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIxOlf7T7iCt","executionInfo":{"status":"ok","timestamp":1692549826700,"user_tz":-120,"elapsed":18127,"user":{"displayName":"Luis LÃ³pez","userId":"16501807039588618285"}},"outputId":"fd438768-d07d-4fc0-b35e-b8fb609df4ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n","Collecting sentencepiece (from sentence-transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n","  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=9b506b72bac92cfe8a382f869fc8f7c7bb103692e41e99ada9ac66fdedf8f645\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence-transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.31.0\n"]}],"source":["!pip install sentence-transformers"]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","from torch import Tensor\n","from transformers import AutoTokenizer, AutoModel\n","import json\n","from google.colab import drive\n","import pandas as pd"],"metadata":{"id":"7J70_HyVJcBT","executionInfo":{"status":"ok","timestamp":1692549828414,"user_tz":-120,"elapsed":1721,"user":{"displayName":"Luis LÃ³pez","userId":"16501807039588618285"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","post_path=\"/content/drive/MyDrive/TFM/Instagram.Post.json\"\n","\n","d = pd.read_csv('/content/drive/MyDrive/TFM/SentenceEmbeddings.csv', header=None)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3NpZA9zJeOO","executionInfo":{"status":"ok","timestamp":1692549881472,"user_tz":-120,"elapsed":53063,"user":{"displayName":"Luis LÃ³pez","userId":"16501807039588618285"}},"outputId":"8256a764-9d5e-4455-824f-0837929f37d6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["done = set(d.iloc[:, 0].tolist())\n"],"metadata":{"id":"WfbXWX44-Vfn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def average_pool(last_hidden_states: Tensor,\n","                 attention_mask: Tensor) -> Tensor:\n","    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n","    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"],"metadata":{"id":"iTLoFt8GN3D2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-small')\n","model = AutoModel.from_pretrained('intfloat/multilingual-e5-small')\n","\n","with open(post_path, \"r\") as input:\n","  inp = json.load(input)\n","  ids = []\n","  caption_batch = []\n","  i =1\n","  for line in inp:\n","    if line[\"id\"][\"$numberLong\"] not in done:\n","      ids.append(line[\"id\"][\"$numberLong\"])\n","      caption_batch.append(f'query: {line[\"caption\"]}')\n","      if i %5 == 0:\n","        try:\n","          batch_dict = tokenizer(caption_batch, max_length=512, padding=True, truncation=True, return_tensors='pt')\n","          outputs = model(**batch_dict)\n","          a = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n","\n","          embeddings = a.detach().numpy()\n","          df_features = pd.DataFrame(embeddings)\n","          df_ids = pd.DataFrame(ids)\n","          merged_df = pd.concat((df_ids, df_features), axis=1)\n","          merged_df.to_csv('/content/drive/MyDrive/TFM/SentenceEmbeddings.csv',  mode='a', header=False, index=False)\n","\n","          caption_batch = []\n","          ids = []\n","        except:\n","          print(caption_batch)\n","\n","      i +=1\n","\n","  batch_dict = tokenizer(caption_batch, max_length=512, padding=True, truncation=True, return_tensors='pt')\n","  outputs = model(**batch_dict)\n","  a = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n","  embeddings = a.detach().numpy()\n","  df_features = pd.DataFrame(embeddings)\n","  df_ids = pd.DataFrame(ids)\n","  merged_df = pd.concat((df_ids, df_features), axis=1)\n","  merged_df.to_csv('/content/drive/MyDrive/TFM/SentenceEmbeddings.csv',  mode='a', header=False, index=False)\n"],"metadata":{"id":"-ufn9jN2_Ga8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1692536653237,"user_tz":-120,"elapsed":5595294,"user":{"displayName":"Luis LÃ³pez","userId":"16501807039588618285"}},"outputId":"0a55d40d-3fdc-4c58-a357-ef6202683c3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['query: âš“ #latiendadeammi âš“ Kit de uÃ±as completo y seguro para tu bebÃ©.ğŸ‘¶ğŸ»ğŸ¼ğŸ§·\\n\\nY la generaciÃ³n que estÃ¡ por nacer, ALABARÃ A DIOS! SALMO 102-18.ğŸ¤°ğŸ¼ğŸ¤±ğŸ¼â¤ï¸\\n\\nNO TE DEJES CONFUNDIR...\\nâ¡ï¸SÃ³lo lo encuentras en nuestra tienda.\\n\\nÂ¡Â¡Â¡ LA ORIGINAL!!! ğŸ”ğŸ’¯% âœ”\\n\\nâ˜† LA TIENDA OFICIAL DE LAS MAMÃS!ğŸ¤°ğŸ¤±ğŸ‘¶ğŸ‘¦ğŸ‘§\\n\\nâ™¡ Â¡SÃ³lo Ternura!â¤\\n\\nY todas las naciones os dirÃ¡n bienaventurados; porque serÃ©is tierra deseable, dice JehovÃ¡ de los ejÃ©rcitos.\\nMalaquÃ­as 3:12\\n\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n\\nâ¡ï¸Siguenos en Facebook e Instagram â¬…ï¸\\n\\nhttps://www.instagram.com/invites/contact/?i=1bsf83k5n737i&utm_content=e0yu0yx\\nâ™¡\\nâ€¢\\nğŸŒSan JosÃ© del Nus (Ant).\\nâ€¢\\nğŸšDespachos Nacionales. ğŸ‡¨ğŸ‡´\\n\\nâ˜ï¸3022571857 - 3104573376.\\nâ€¢\\n#TodoParaBebÃ©  #tetero  #mibebÃ© #babyshower #ropabebe #mamaprimeriza #mamafeliz #esperandobebe  #baberospersonalizados #baby #niÃ±osyniÃ±asfelices #paÃ±alera #bebes #bebeencamino #bebeabordo #colorespasteles #regalosoriginales #regalosunicos #niÃ±osfelicespadresfelices #cobijasbebe  #ropaniÃ±os #lactanciamaterna #ajuarbebe #ajuardebebe #ajuar #primerdia #baberosbebe  #NoAlAbortoSiALaVida #NoAlAborto', 'query: âš“ #latiendadeammi âš“ Promueve el desarrollo de tu bebÃ© en brazos y piernas con nuestro gimnasio mientras juega.ğŸ‘¶ğŸ»ğŸ§®ğŸ§·ğŸ¼\\n\\nY la generaciÃ³n que estÃ¡ por nacer, ALABARÃ A DIOS! SALMO 102-18.ğŸ¤°ğŸ¼ğŸ¤±ğŸ¼â¤ï¸\\n\\nNO TE DEJES CONFUNDIR...\\nâ¡ï¸SÃ³lo lo encuentras en nuestra tienda.\\n\\nÂ¡Â¡Â¡ LA ORIGINAL!!! ğŸ”ğŸ’¯% âœ”\\n\\nâ˜† LA TIENDA OFICIAL DE LAS MAMÃS!ğŸ¤°ğŸ¤±ğŸ‘¶ğŸ‘¦ğŸ‘§\\n\\nâ™¡ Â¡SÃ³lo Ternura!â¤\\n\\nY todas las naciones os dirÃ¡n bienaventurados; porque serÃ©is tierra deseable, dice JehovÃ¡ de los ejÃ©rcitos.\\nMalaquÃ­as 3:12\\n\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n\\nâ¡ï¸Siguenos en Facebook e Instagram â¬…ï¸\\n\\nhttps://www.instagram.com/invites/contact/?i=1bsf83k5n737i&utm_content=e0yu0yx\\nâ™¡\\nâ€¢\\nğŸŒSan JosÃ© del Nus (Ant).\\nâ€¢\\nğŸšDespachos Nacionales. ğŸ‡¨ğŸ‡´\\n\\nâ˜ï¸3022571857 - 3104573376.\\nâ€¢\\n#TodoParaBebÃ©  #tetero  #mibebÃ© #babyshower #ropabebe #mamaprimeriza #mamafeliz #esperandobebe  #baberospersonalizados #baby #niÃ±osyniÃ±asfelices #paÃ±alera #bebes #bebeencamino #bebeabordo #colorespasteles #regalosoriginales #regalosunicos #niÃ±osfelicespadresfelices #cobijasbebe  #ropaniÃ±os #lactanciamaterna #ajuarbebe #ajuardebebe #ajuar #primerdia #baberosbebe  #NoAlAbortoSiALaVida #NoAlAborto', 'query: âš“ #latiendadeammi âš“ Protege los espacios de tu bebÃ©, decora su habitaciÃ³n con este colorido tapete con figuras y letras. ğŸ°ğŸ‡ğŸ’ğŸ‰\\n\\nY la generaciÃ³n que estÃ¡ por nacer, ALABARÃ A DIOS! SALMO 102-18.ğŸ¤°ğŸ¼ğŸ¤±ğŸ¼â¤ï¸\\n\\nNO TE DEJES CONFUNDIR...\\nâ¡ï¸SÃ³lo lo encuentras en nuestra tienda.\\n\\nÂ¡Â¡Â¡ LA ORIGINAL!!! ğŸ”ğŸ’¯% âœ”\\n\\nâ˜† LA TIENDA OFICIAL DE LAS MAMÃS!ğŸ¤°ğŸ¤±ğŸ‘¶ğŸ‘¦ğŸ‘§\\n\\nâ™¡ Â¡SÃ³lo Ternura!â¤\\n\\nY todas las naciones os dirÃ¡n bienaventurados; porque serÃ©is tierra deseable, dice JehovÃ¡ de los ejÃ©rcitos.\\nMalaquÃ­as 3:12\\n\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n\\nâ¡ï¸Siguenos en Facebook e Instagram â¬…ï¸\\n\\nhttps://www.instagram.com/invites/contact/?i=1bsf83k5n737i&utm_content=e0yu0yx\\nâ™¡\\nâ€¢\\nğŸŒSan JosÃ© del Nus (Ant).\\nâ€¢\\nğŸšDespachos Nacionales. ğŸ‡¨ğŸ‡´\\n\\nâ˜ï¸3022571857 - 3104573376.\\nâ€¢\\n#TodoParaBebÃ©  #tetero  #mibebÃ© #babyshower #ropabebe #mamaprimeriza #mamafeliz #esperandobebe  #baberospersonalizados #baby #niÃ±osyniÃ±asfelices #paÃ±alera #bebes #bebeencamino #bebeabordo #colorespasteles #regalosoriginales #regalosunicos #niÃ±osfelicespadresfelices #cobijasbebe  #ropaniÃ±os #lactanciamaterna #ajuarbebe #ajuardebebe #ajuar #primerdia #baberosbebe  #NoAlAbortoSiALaVida #NoAlAborto', 'query: âš“ #latiendadeammi âš“ Al mal tiempo... Una colorida y calientita chaqueta!â˜”ğŸ’¦ğŸ¥¶ğŸ§¡ğŸ’™\\n\\nY la generaciÃ³n que estÃ¡ por nacer, ALABARÃ A DIOS! SALMO 102-18.ğŸ¤°ğŸ¼ğŸ¤±ğŸ¼â¤ï¸\\n\\nNO TE DEJES CONFUNDIR...\\nâ¡ï¸SÃ³lo lo encuentras en nuestra tienda.\\n\\nÂ¡Â¡Â¡ LA ORIGINAL!!! ğŸ”ğŸ’¯% âœ”\\n\\nâ˜† LA TIENDA OFICIAL DE LAS MAMÃS!ğŸ¤°ğŸ¤±ğŸ‘¶ğŸ‘¦ğŸ‘§\\n\\nâ™¡ Â¡SÃ³lo Ternura!â¤\\n\\nY todas las naciones os dirÃ¡n bienaventurados; porque serÃ©is tierra deseable, dice JehovÃ¡ de los ejÃ©rcitos.\\nMalaquÃ­as 3:12\\n\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n\\nâ¡ï¸Siguenos en Facebook e Instagram â¬…ï¸\\n\\nhttps://www.instagram.com/invites/contact/?i=1bsf83k5n737i&utm_content=e0yu0yx\\nâ™¡\\nâ€¢\\nğŸŒSan JosÃ© del Nus (Ant).\\nâ€¢\\nğŸšDespachos Nacionales. ğŸ‡¨ğŸ‡´\\n\\nâ˜ï¸3022571857 - 3104573376.\\nâ€¢\\n#TodoParaBebÃ©  #tetero  #mibebÃ© #babyshower #ropabebe #mamaprimeriza #mamafeliz #esperandobebe  #baberospersonalizados #baby #niÃ±osyniÃ±asfelices #paÃ±alera #bebes #bebeencamino #bebeabordo #colorespasteles #regalosoriginales #regalosunicos #niÃ±osfelicespadresfelices #cobijasbebe  #ropaniÃ±os #lactanciamaterna #ajuarbebe #ajuardebebe #ajuar #primerdia #baberosbebe  #NoAlAbortoSiALaVida #NoAlAborto', 'query: âš“ #latiendadeammi âš“ LlegÃ³ el invierno, y que tal un buso muy colorido para mantener abrigadito a tu pequeÃ±o? Infaltable en su closet! â˜”ğŸ’¦ğŸ¥¶\\n\\nY la generaciÃ³n que estÃ¡ por nacer, ALABARÃ A DIOS! SALMO 102-18.ğŸ¤°ğŸ¼ğŸ¤±ğŸ¼â¤ï¸\\n\\nNO TE DEJES CONFUNDIR...\\nâ¡ï¸SÃ³lo lo encuentras en nuestra tienda.\\n\\nÂ¡Â¡Â¡ LA ORIGINAL!!! ğŸ”ğŸ’¯% âœ”\\n\\nâ˜† LA TIENDA OFICIAL DE LAS MAMÃS!ğŸ¤°ğŸ¤±ğŸ‘¶ğŸ‘¦ğŸ‘§\\n\\nâ™¡ Â¡SÃ³lo Ternura!â¤\\n\\nY todas las naciones os dirÃ¡n bienaventurados; porque serÃ©is tierra deseable, dice JehovÃ¡ de los ejÃ©rcitos.\\nMalaquÃ­as 3:12\\n\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n\\nâ¡ï¸Siguenos en Facebook e Instagram â¬…ï¸\\n\\nhttps://www.instagram.com/invites/contact/?i=1bsf83k5n737i&utm_content=e0yu0yx\\nâ™¡\\nâ€¢\\nğŸŒSan JosÃ© del Nus (Ant).\\nâ€¢\\nğŸšDespachos Nacionales. ğŸ‡¨ğŸ‡´\\n\\nâ˜ï¸3022571857 - 3104573376.\\nâ€¢\\n#TodoParaBebÃ©  #tetero  #mibebÃ© #babyshower #ropabebe #mamaprimeriza #mamafeliz #esperandobebe  #baberospersonalizados #baby #niÃ±osyniÃ±asfelices #paÃ±alera #bebes #bebeencamino #bebeabordo #colorespasteles #regalosoriginales #regalosunicos #niÃ±osfelicespadresfelices #cobijasbebe  #ropaniÃ±os #lactanciamaterna #ajuarbebe #ajuardebebe #ajuar #primerdia #baberosbebe  #NoAlAbortoSiALaVida #NoAlAborto']\n"]},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-28346c7be9c7>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mbatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaption_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2577\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   2664\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2854\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m   2855\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msanitized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-28346c7be9c7>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intfloat/multilingual-e5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/TFM/SentenceEmbeddings.csv', header=None)\n","\n","# Drop duplicates based on all columns\n","df.drop_duplicates(subset=df.columns[0], inplace=True)\n","\n","df.to_csv('/content/drive/MyDrive/TFM/SentenceEmbeddings.csv',  mode='w', header=False, index=False)"],"metadata":{"id":"tRP5YuguNNgS","executionInfo":{"status":"ok","timestamp":1692549908706,"user_tz":-120,"elapsed":18112,"user":{"displayName":"Luis LÃ³pez","userId":"16501807039588618285"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NVp4aHNB-a2P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"zGp1fZEBo3wz","executionInfo":{"status":"error","timestamp":1692479601672,"user_tz":-120,"elapsed":8,"user":{"displayName":"Luis LÃ³pez","userId":"16501807039588618285"}},"outputId":"29d44713-2f44-4715-9f2e-96d3f9ce2262"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-5098ab42f864>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YL8D04UZo7AA"},"execution_count":null,"outputs":[]}]}